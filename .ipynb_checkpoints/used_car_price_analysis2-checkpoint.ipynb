{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöó Used Car Selling Price Analysis\n",
    "\n",
    "## Project Overview\n",
    "This notebook analyzes factors influencing the selling price of used cars. We'll explore a dataset containing various car attributes to help understand what drives prices in the used car market.\n",
    "\n",
    "### Problem Statement\n",
    "Our friend Otis wants to sell his car but isn't sure about the price. He wants to maximize profit while ensuring a reasonable deal for buyers. To help Otis, we'll analyze the dataset and determine the factors affecting car prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data analysis and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Prepare the Dataset\n",
    "\n",
    "First, we'll load the dataset and remove any unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Note: Make sure 'output.csv' is in the same directory as this notebook\n",
    "try:\n",
    "    df = pd.read_csv('output.csv')\n",
    "    # Remove the first column if it's an index\n",
    "    df = df.iloc[:, 1:]\n",
    "    print(\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Error: 'output.csv' not found. Please ensure the file is in the correct directory.\")\n",
    "    print(\"You can download the dataset from the tutorial link.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Assign Column Headers\n",
    "\n",
    "The dataset doesn't have column names, so we'll assign descriptive headers based on the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column headers\n",
    "headers = [\"symboling\", \"normalized-losses\", \"make\", \"fuel-type\", \"aspiration\",\n",
    "           \"num-of-doors\", \"body-style\", \"drive-wheels\", \"engine-location\",\n",
    "           \"wheel-base\", \"length\", \"width\", \"height\", \"curb-weight\",\n",
    "           \"engine-type\", \"num-of-cylinders\", \"engine-size\", \"fuel-system\",\n",
    "           \"bore\", \"stroke\", \"compression-ratio\", \"horsepower\", \"peak-rpm\",\n",
    "           \"city-mpg\", \"highway-mpg\", \"price\"]\n",
    "\n",
    "# Assign headers to the dataframe\n",
    "df.columns = headers\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(\"‚úÖ Column headers assigned successfully!\")\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Check for Missing Values\n",
    "\n",
    "It's important to identify any missing values that might affect our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isna().any())\n",
    "\n",
    "# Count total missing values\n",
    "print(f\"\\nTotal missing values: {df.isna().sum().sum()}\")\n",
    "\n",
    "# Display columns with missing values and their counts\n",
    "missing_cols = df.columns[df.isna().any()].tolist()\n",
    "if missing_cols:\n",
    "    print(\"\\nColumns with missing values:\")\n",
    "    for col in missing_cols:\n",
    "        print(f\"{col}: {df[col].isna().sum()} missing values\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Convert MPG to L/100km\n",
    "\n",
    "Since fuel consumption is measured differently in different regions, we'll convert miles per gallon (MPG) to liters per 100 kilometers (L/100km)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataframe to work with\n",
    "data = df.copy()\n",
    "\n",
    "# Convert city-mpg to L/100km (235 / MPG)\n",
    "data['city-mpg'] = 235 / data['city-mpg']\n",
    "\n",
    "# Rename the column to reflect the new unit\n",
    "data.rename(columns={'city-mpg': 'city-L/100km'}, inplace=True)\n",
    "\n",
    "print(\"‚úÖ MPG to L/100km conversion completed!\")\n",
    "print(\"\\nUpdated column names:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Clean and Convert Price Column\n",
    "\n",
    "The price column may contain '?' as missing values. We need to clean it and convert to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in price column\n",
    "print(\"Unique values in price column:\")\n",
    "print(data['price'].unique()[:10])  # Show first 10 unique values\n",
    "\n",
    "# Remove rows where price is '?'\n",
    "data = data[data['price'] != '?']\n",
    "\n",
    "# Convert price to integer\n",
    "data['price'] = data['price'].astype(int)\n",
    "\n",
    "print(\"\\n‚úÖ Price column cleaned and converted to integer!\")\n",
    "print(f\"Price range: ${data['price'].min():,} - ${data['price'].max():,}\")\n",
    "print(f\"Average price: ${data['price'].mean():,.2f}\")\n",
    "\n",
    "print(\"\\nUpdated data types:\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Normalize Features\n",
    "\n",
    "To ensure fair comparisons between different features, we normalize numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize length, width, and height (scale to 0-1 range)\n",
    "data['length'] = data['length'] / data['length'].max()\n",
    "data['width'] = data['width'] / data['width'].max()\n",
    "data['height'] = data['height'] / data['height'].max()\n",
    "\n",
    "print(\"‚úÖ Length, width, and height normalized!\")\n",
    "print(\"\\nAfter normalization (values should be between 0 and 1):\")\n",
    "print(f\"Length range: {data['length'].min():.3f} - {data['length'].max():.3f}\")\n",
    "print(f\"Width range: {data['width'].min():.3f} - {data['width'].max():.3f}\")\n",
    "print(f\"Height range: {data['height'].min():.3f} - {data['height'].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Create Price Categories (Binning)\n",
    "\n",
    "We'll categorize cars based on their price into three categories: Low, Medium, and High."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for price categorization\n",
    "bins = np.linspace(min(data['price']), max(data['price']), 4)\n",
    "group_names = ['Low', 'Medium', 'High']\n",
    "\n",
    "# Create a new column with price categories\n",
    "data['price-binned'] = pd.cut(data['price'], bins, \n",
    "                              labels=group_names, \n",
    "                              include_lowest=True)\n",
    "\n",
    "print(\"‚úÖ Price categories created!\")\n",
    "print(\"\\nDistribution of price categories:\")\n",
    "print(data['price-binned'].value_counts())\n",
    "\n",
    "# Visualize the distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "data['price-binned'].value_counts().plot(kind='bar', color=['green', 'yellow', 'red'])\n",
    "plt.title('Distribution of Price Categories')\n",
    "plt.xlabel('Price Category')\n",
    "plt.ylabel('Number of Cars')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Convert Categorical Data to Numerical\n",
    "\n",
    "Machine learning models require numerical data. We'll demonstrate one-hot encoding for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Convert 'fuel-type' to dummy variables\n",
    "fuel_dummies = pd.get_dummies(data['fuel-type'])\n",
    "print(\"One-hot encoding for fuel-type (first 5 rows):\")\n",
    "fuel_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistical summary of numerical columns\n",
    "print(\"Statistical summary of numerical features:\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Data Visualization\n",
    "\n",
    "Let's create various visualizations to understand the relationships in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot of price distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(data['price'])\n",
    "plt.title('Box Plot of Car Prices')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Price statistics:\")\n",
    "print(f\"Median: ${data['price'].median():,.2f}\")\n",
    "print(f\"Q1: ${data['price'].quantile(0.25):,.2f}\")\n",
    "print(f\"Q3: ${data['price'].quantile(0.75):,.2f}\")\n",
    "print(f\"IQR: ${data['price'].quantile(0.75) - data['price'].quantile(0.25):,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot of price by drive-wheels\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='drive-wheels', y='price', data=data)\n",
    "plt.title('Price Distribution by Drive Wheels Type')\n",
    "plt.xlabel('Drive Wheels')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of engine size vs price\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data['engine-size'], data['price'], alpha=0.6)\n",
    "plt.title('Engine Size vs Price')\n",
    "plt.xlabel('Engine Size')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = data['engine-size'].corr(data['price'])\n",
    "print(f\"Correlation between engine size and price: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Group Analysis\n",
    "\n",
    "Let's analyze average prices by drive-wheels and body-style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns and group by drive-wheels and body-style\n",
    "test = data[['drive-wheels', 'body-style', 'price']]\n",
    "data_grp = test.groupby(['drive-wheels', 'body-style'], \n",
    "                        as_index=False).mean()\n",
    "\n",
    "print(\"Average price by drive-wheels and body-style:\")\n",
    "data_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table for better visualization\n",
    "data_pivot = data_grp.pivot(index='drive-wheels',\n",
    "                            columns='body-style',\n",
    "                            values='price')\n",
    "\n",
    "print(\"Pivot table of average prices:\")\n",
    "data_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of the pivot table\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data_pivot, annot=True, cmap='RdBu', fmt='.0f', \n",
    "            linewidths=1, cbar_kws={'label': 'Average Price ($)'})\n",
    "plt.title('Average Price Heatmap: Drive Wheels vs Body Style')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Statistical Analysis - ANOVA Test\n",
    "\n",
    "Let's perform an ANOVA test to determine if there's a significant price difference between Honda and Subaru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for ANOVA\n",
    "data_annova = data[['make', 'price']]\n",
    "grouped_annova = data_annova.groupby(['make'])\n",
    "\n",
    "# Perform ANOVA test between Honda and Subaru\n",
    "try:\n",
    "    annova_results_l = sp.stats.f_oneway(\n",
    "        grouped_annova.get_group('honda')['price'],\n",
    "        grouped_annova.get_group('subaru')['price']\n",
    "    )\n",
    "    \n",
    "    print(\"ANOVA Test Results: Honda vs Subaru\")\n",
    "    print(f\"F-statistic: {annova_results_l.statistic:.4f}\")\n",
    "    print(f\"P-value: {annova_results_l.pvalue:.4f}\")\n",
    "    \n",
    "    if annova_results_l.pvalue < 0.05:\n",
    "        print(\"‚úÖ Result: Significant difference in prices (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"‚ùå Result: No significant difference in prices (p >= 0.05)\")\n",
    "        \n",
    "except KeyError as e:\n",
    "    print(f\"‚ùå Error: {e}. Make sure 'honda' and 'subaru' exist in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression plot of engine size vs price\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(x='engine-size', y='price', data=data, scatter_kws={'alpha':0.5})\n",
    "plt.title('Engine Size vs Price with Regression Line')\n",
    "plt.xlabel('Engine Size')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.ylim(0, )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "Based on our analysis, we've discovered several key insights:\n",
    "\n",
    "1. **Engine Size Impact**: There's a strong positive correlation between engine size and price, suggesting larger engines command higher prices.\n",
    "\n",
    "2. **Drive Wheels Influence**: The type of drive wheels significantly affects pricing, with certain configurations consistently priced higher.\n",
    "\n",
    "3. **Body Style Variations**: Different body styles show distinct price patterns when combined with drive wheel types.\n",
    "\n",
    "4. **Statistical Significance**: The ANOVA test helps validate whether observed price differences between brands are statistically meaningful.\n",
    "\n",
    "### Recommendations for Otis:\n",
    "* Focus on key features like engine size and drive wheels when determining a fair price\n",
    "* Compare similar body styles and brands in the market\n",
    "* Use the visualizations to understand where his car fits in the overall price distribution\n",
    "\n",
    "### Next Steps:\n",
    "* Consider building a predictive model to estimate price based on features\n",
    "* Explore more advanced feature engineering\n",
    "* Analyze additional factors like mileage and condition if data becomes available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset information\n",
    "print(\"Final dataset shape:\", data.shape)\n",
    "print(\"\\nColumns in final dataset:\")\n",
    "for col in data.columns:\n",
    "    print(f\"- {col}: {data[col].dtype}\")\n",
    "\n",
    "print(\"\\n‚úÖ Analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
